{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring UCC cluster data\n",
        "\n",
        "This notebook allows you to explore the data for each cluster listed in the UCC. The UCC cluster datafiles contain the frame processed by the [fastMP](https://asteca.readthedocs.io/en/latest/apidocs/asteca/asteca.membership.html#asteca.membership.Membership.fastmp) membership algorithm.\n",
        "\n",
        "Alternatively, you can also access the datafiles for the [Hunt & Reffert (2023)](https://ui.adsabs.harvard.edu/abs/2023A%26A...673A.114H) (HUNT23) and [Cantat-Gaudin et al. (2020)](https://ui.adsabs.harvard.edu/abs/2020A%26A...640A...1C) (CANTAT20) articles if available for a given cluster."
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages and load data\n",
        "\n",
        "First we define the name of the cluster to be analyzed. In this example we select the cluster `Blanco 1` (it doesn't matter if you use upper or lower case):"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster = \"blanco 1\""
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then import the required packages:"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": ""
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from urllib.error import HTTPError\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.models import LinearColorMapper\n",
        "from bokeh.models import ColumnDataSource\n",
        "from bokeh.models import ColorBar\n",
        "from bokeh.models import Range1d\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to load the cluster data into a `pandas` dataframe. To do this we first need to define the function that handles the loading.\n"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cluster(cluster, db_id):\n",
        "    \"\"\"Function that handles loading a cluster's datafile in any of the\n",
        "    UCC, HUNT23 or CANTAT20 databases, from the UCC repositories.\"\"\"\n",
        "    # Proper file name format\n",
        "    file_name = cluster.lower().replace('_', '').replace(' ', '').replace('-', '')\n",
        "    # Proper databse name format\n",
        "    _db_id = '_'+db_id if db_id != 'UCC' else ''\n",
        "    # Check all repositories where datafiles are stored\n",
        "    for qfolder in ('1N', '1P', '2N', '2P', '3N', '3P', '4N', '4P'):\n",
        "        try:\n",
        "            repo_root = f\"https://github.com/ucc23/Q{qfolder}/raw/main/datafiles/\"\n",
        "            path = repo_root + file_name + f\"{_db_id}.parquet\"\n",
        "            df = pd.read_parquet(path)\n",
        "            print(f\"Cluster '{cluster}' loaded from '{db_id}' database\")\n",
        "            return df\n",
        "        except HTTPError:\n",
        "            pass\n",
        "    raise ValueError(f\"Cluster '{cluster}' not found in {db_id} database\")"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now load a cluster with data from the UCC, HUNT23 or CANTAT20, assuming that cluster was processed in either of those articles. To do this select either `UCC`, `HUNT23` or `CANTAT20` in the `db_id` variable below and load."
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_id = 'UCC'\n",
        "# db_id = 'HUNT23'\n",
        "# db_id = 'CANTAT20'\n",
        "\n",
        "# Load the dataframe\n",
        "df = load_cluster(cluster, db_id)"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most probable members in the UCC database are stored using a probability cut of `P>0.5`. A minimum number of member stars is set to `25`, so that if less than `25` stars have `P>0.5` then the most probable members are those `25` stars with the largest probability values below 0.5. Other databases handle this differently."
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define plotting functions\n"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define functions to generate scatter plots and histograms:"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scatter_plot(x, y, col, flip_yaxis=False):\n",
        "    members = ColumnDataSource({'xm':df[x], 'ym':df[y], 'col':df[col]})\n",
        "    cmap = LinearColorMapper(palette=\"Viridis256\", low = .5, high = 1)\n",
        "\n",
        "    p = figure()\n",
        "    p.scatter(\"xm\", \"ym\", size=10, source=members, line_color='black', alpha=.75,\n",
        "              fill_color={\"field\":\"col\", \"transform\":cmap})\n",
        "    if flip_yaxis:\n",
        "        p.y_range.flipped = True\n",
        "    bar = ColorBar(color_mapper=cmap)\n",
        "    p.add_layout(bar, \"right\")\n",
        "    p.xaxis.axis_label = x\n",
        "    p.yaxis.axis_label = y\n",
        "    show(p)\n",
        "\n",
        "\n",
        "def histo_plot(x):\n",
        "    p = figure()\n",
        "    # Histogram for member stars\n",
        "    hist, edges = np.histogram(df[x], bins=20)\n",
        "    p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:],\n",
        "            fill_color=\"skyblue\", line_color=\"white\", alpha=.75)\n",
        "    # Vertical line\n",
        "    p.ray(x=[np.nanmedian(df[x])], y=[0], length=0, angle=90,\n",
        "          angle_units='deg', line_width=3, line_color='red')\n",
        "    left, right = np.nanmin(df[x]) * 0.9, np.nanmax(df[x]) * 1.1\n",
        "    p.x_range=Range1d(left, right)\n",
        "    p.xaxis.axis_label = x\n",
        "    p.yaxis.axis_label = \"N\"\n",
        "    show(p)"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate interactive plots\n",
        "\n",
        "Now we can generate some interactive plots. For example the distribution of galactic coordinates for member stars, colored by their membership probability"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y, col = 'GLON', 'GLAT', 'probs'\n",
        "scatter_plot(x, y, col)"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And a color-magnitude diagram"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y, col = 'BP-RP', 'Gmag', 'probs'\n",
        "scatter_plot(x, y, col, True)"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution of proper motions"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y, col = 'pmRA', 'pmDE', 'probs'\n",
        "scatter_plot(x, y, col)"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram of the parallaxes with the median value of the selected members shown as a red vertical line"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histo_plot('Plx')"
      ],
      "metadata": {
        "id": "zG7GwSEgptgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing with ASteCA\n",
        "\n",
        "The loaded datafile with members for a given cluster can also be analyzed with the [ASteCA](https://asteca.github.io/) package."
      ],
      "metadata": {
        "id": "y6kRVlNPA1jB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install latest published versions of ASteCA and PyABC\n",
        "!pip install asteca\n",
        "!pip install pyabc\n",
        "\n",
        "# Import required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tempfile\n",
        "import datetime as dt\n",
        "import asteca\n",
        "import pyabc"
      ],
      "metadata": {
        "id": "HRzvcKwABI3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a 'cluster' object loading the cluster's data\n",
        "my_cluster = asteca.cluster(\n",
        "    obs_df=df,\n",
        "    ra='RA_ICRS',\n",
        "    dec='DE_ICRS',\n",
        "    magnitude=\"Gmag\",\n",
        "    e_mag=\"e_Gmag\",\n",
        "    color=\"BP-RP\",\n",
        "    e_color='e_BP-RP'\n",
        ")\n",
        "\n",
        "# Load the isochrone(s) file(s). The file(s) must be located in a 'isoch/' folder within this Colab session\n",
        "isochs = asteca.isochrones(\n",
        "    model=\"PARSEC\",\n",
        "    isochs_path=\"isoch/\",\n",
        "    magnitude=\"Gmag\",\n",
        "    color=(\"G_BPmag\", \"G_RPmag\"),\n",
        "    magnitude_effl=6390.7,\n",
        "    color_effl=(5182.58, 7825.08),\n",
        ")\n",
        "\n",
        "# Instantiate a 'synthetic' object using the isochrones\n",
        "synthcl = asteca.synthetic(isochs)\n",
        "\n",
        "# Define the paramters that are fixed, not fitted\n",
        "fix_params = {\"alpha\": 0.09, \"beta\": 0.94, \"Rv\": 3.1, \"DR\": 0.0, \"met\": 0.152}\n",
        "\n",
        "# Calibrate the 'synthetic' object\n",
        "synthcl.calibrate(my_cluster, fix_params)"
      ],
      "metadata": {
        "id": "9pFpMRIIBSfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm_min, dm_max = 0, 4\n",
        "Av_min, Av_max = 0, .25\n",
        "loga_min, loga_max = 6, 8.5\n",
        "\n",
        "priors = {\n",
        "    \"loga\": [loga_min, loga_max],\n",
        "    \"dm\": [dm_min, dm_max],\n",
        "    \"Av\": [Av_min, Av_max],\n",
        "}\n",
        "\n",
        "priors = pyabc.Distribution(\n",
        "    **{\n",
        "        p: pyabc.RV(\"uniform\", priors[p][0], priors[p][1] - priors[p][0])\n",
        "        for p in priors\n",
        "    }\n",
        ")\n",
        "\n",
        "# Define likelihood\n",
        "likelihood = asteca.likelihood(my_cluster)\n",
        "max_lkl = likelihood.max_lkl\n",
        "\n",
        "def model(fit_params):\n",
        "    \"\"\"Generate synthetic cluster.\"\"\"\n",
        "    synth_clust = synthcl.generate(fit_params)\n",
        "    # pyABC expects a dictionary from this function\n",
        "    return {\"data\": synth_clust}\n",
        "\n",
        "def distance(synth, obs):\n",
        "    \"\"\"\n",
        "    The likelihood is maximized for better fitted models but this distance requires\n",
        "    minimization. Hence we normalize and invert.\n",
        "    \"\"\"\n",
        "    lkl = likelihood.get(synth[\"data\"])\n",
        "    return 1 - lkl / max_lkl\n",
        "    # return lkl\n",
        "\n",
        "# Define pyABC parameters\n",
        "pop_size = 100\n",
        "max_mins = 5\n",
        "n_procs = 2\n",
        "abc = pyabc.ABCSMC(\n",
        "    model,\n",
        "    priors,\n",
        "    distance,\n",
        "    population_size=pop_size,\n",
        "    sampler=pyabc.sampler.MulticoreEvalParallelSampler(n_procs=n_procs),\n",
        ")\n",
        "# This is a temporary file required by pyABC\n",
        "db_path = \"sqlite:///\" + os.path.join(tempfile.gettempdir(), \"pyABC.db\")\n",
        "abc.new(db_path)\n",
        "# Run pyABC\n",
        "history = abc.run(\n",
        "    # min_acceptance_rate=min_acceptance_rate,\n",
        "    max_walltime=dt.timedelta(hours=0, minutes=max_mins),\n",
        ")\n",
        "# Extract last iteration and weights\n",
        "df, w = history.get_distribution()\n",
        "\n",
        "print(f\"\\nESS: {pyabc.weighted_statistics.effective_sample_size(w):.3f}\")\n",
        "final_dist = pyabc.inference_util.eps_from_hist(history)\n",
        "print(f\"Dist: {final_dist:.3f}\")\n",
        "\n",
        "# Define a dictionary of model parameters (those that were not fitted) and their uncertainties\n",
        "fit_model, fit_model_std = {}, {}\n",
        "for k in df.keys():\n",
        "    _median = pyabc.weighted_statistics.weighted_median(df[k].values, w)\n",
        "    _std = pyabc.weighted_statistics.weighted_std(df[k].values, w)\n",
        "    fit_model[k] = _median\n",
        "    fit_model_std[k] = _std\n",
        "    print(f\"{k}: {_median:.4f} +/- {_std:.4f}\")\n",
        "\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "asteca.plot.cluster(my_cluster, ax1)\n",
        "isoch_arr = asteca.plot.get_isochrone(synthcl, fit_model)\n",
        "asteca.plot.synthetic(synthcl, ax2, fit_model, isoch_arr)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OV-p0Av0BoTE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
